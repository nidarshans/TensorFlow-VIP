{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qoo-KMQYXRtE"
      },
      "source": [
        "# CELL 1 (do not change)\n",
        "\"\"\"import statements and boiler plate code\"\"\"\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf \n",
        "import tensorflow.keras as ks\n",
        "import tensorflow.keras.backend as K\n",
        "import tensorflow_probability as tfp\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from typing import *\n",
        "import sys\n",
        "\n",
        "if sys.version_info >= (3, 8, 0):\n",
        "    from math import prod\n",
        "else:\n",
        "    # math.prod shim for Python 3.7 and older\n",
        "    def prod(iterable, *, start=1):\n",
        "        total = start\n",
        "        for element in iterable:\n",
        "            total *= element\n",
        "        return (total)\n",
        "\n",
        "def pretruberate(latent, model, bit, value):\n",
        "    if not isinstance(latent, np.ndarray):\n",
        "        latent = latent.numpy()\n",
        "    latent[0][bit] = step\n",
        "    return model.decode(latent)\n",
        "\n",
        "def pretruberate_range(latent, image, model, bit, vals):\n",
        "    fig, ax = plt.subplots(1, 11)\n",
        "    fig.set_size_inches(w = 15, h = 30)\n",
        "    for i, step in enumerate(vals):\n",
        "        rec = pretruberate(latent, model, bit, step)\n",
        "        ax[i].imshow(rec[0, :, :, 0])\n",
        "        ax[i].axis('off')\n",
        "    ax[10].imshow(image[0, :, :, 0])\n",
        "    ax[10].axis('off')\n",
        "    plt.show()\n",
        "    pass\n",
        "\n",
        "def get_sample(val, index, model, batch_size = None):\n",
        "    sample = val.skip(index).take(1)\n",
        "    for image, label in sample:\n",
        "        break\n",
        "    if batch_size is None:\n",
        "        latent = model.predict(image).numpy()\n",
        "    else:\n",
        "        latent = model.predict(image, batch_size = batch_size).numpy()\n",
        "    return image, latent\n",
        "\n",
        "\n",
        "def display(val, model, n = 10, x0 = 0, y0 = 1): \n",
        "    image, latent = get_sample(val, 11, model)\n",
        "    latent = model.predict(image).numpy()\n",
        "    latent = latent[0, :]\n",
        "    print(latent.shape)\n",
        "    norm = tfp.distributions.Normal(0,1)\n",
        "    vals_x = norm.quantile(np.linspace(0.05, 0.95, n))\n",
        "    vals_y = norm.quantile(np.linspace(0.05, 0.95, n))\n",
        "\n",
        "    fig, ax = plt.subplots(n, n)\n",
        "    fig.set_size_inches(w = 10, h = 10)\n",
        "    for i, x in enumerate(vals_x):\n",
        "        for j, y in enumerate(vals_y):\n",
        "            latent[x0], latent[y0] = x, y\n",
        "            rec = tf.sigmoid(model.decode(np.array([latent])))\n",
        "            ax[i, j].imshow(rec[0,:,:,0], cmap='gnuplot2')\n",
        "            ax[i, j].axis('off')\n",
        "    plt.subplots_adjust(wspace=0, hspace=0, left=0, right=1, bottom=0, top=1)\n",
        "    plt.show()\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGDU_opHZl-t"
      },
      "source": [
        "# CELL 2\n",
        "def preprocess(image: tf.Tensor, label: tf.Tensor, disp: bool = False):\n",
        "    # TODO: fill in this function\n",
        "    randint = NotImplemented\n",
        "    \n",
        "    if disp:\n",
        "        tf.print(\"random value: \", randint)\n",
        "    return image, image\n",
        "\n",
        "\"\"\"script to load data set and print info\"\"\"\n",
        "(train, test), info = tfds.load(\"mnist\", split = ['train', 'test'], with_info=True, shuffle_files=True, as_supervised = True)\n",
        "print(info)\n",
        "\n",
        "\"\"\" Test \"\"\"\n",
        "train = train.map(lambda x, y: preprocess(x, y, disp = True)).batch(1)\n",
        "for i, (image, _) in enumerate(train):\n",
        "    plt.imshow(image[0, ..., 0])\n",
        "    plt.show()\n",
        "    if i > 10:\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5u2G0n1Yir0t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "97f6a9d5-d851-4e6a-9f7e-7fc9935ea0f1"
      },
      "source": [
        "# CELL 3\n",
        "\"\"\" Custom Building Blocks \"\"\"\n",
        "class ResidualBlock(ks.layers.Layer):\n",
        "    def __init__(self, \n",
        "                 filters: int, \n",
        "                 dilation_rate: Tuple[int, int] = (1,1), \n",
        "                 kernel_initializer: str = 'glorot_uniform', \n",
        "                 momentum: float = 0.99, \n",
        "                 epsilon: float = 0.001, \n",
        "                 downsample: bool = False,\n",
        "                 use_bias: bool = False, \n",
        "                 use_sync: bool = True, \n",
        "                 kernel_regularizer = None, \n",
        "                 bias_regularizer = None):\n",
        "        \n",
        "        # parameters Conv2D\n",
        "        self._filters = filters\n",
        "        self._dilation_rate = dilation_rate\n",
        "        self._kernel_initializer = kernel_initializer\n",
        "        self._kernel_regularizer = kernel_regularizer\n",
        "        self._bias_regularizer = bias_regularizer\n",
        "        self._use_bias = use_bias\n",
        "        self._use_sync = use_sync\n",
        "\n",
        "        # parameters Batch Norm\n",
        "        if K.image_data_format() == \"channels_last\":\n",
        "            # channels_last: (batch_size, height, width, channels)\n",
        "            self._axis = -1\n",
        "        else:\n",
        "            # not channels_last: (batch_size, channels, height, width)\n",
        "            self._axis = 1\n",
        "\n",
        "        self._momentum = momentum \n",
        "        self._epsilon = epsilon \n",
        "\n",
        "        # downsample\n",
        "        self._downsample = downsample\n",
        "\n",
        "        if downsample:\n",
        "            self._strides = (2,2)\n",
        "        else:\n",
        "            self._strides = (1,1)\n",
        "\n",
        "        # TODO: set the activation function to the same one that is used in the paper\n",
        "        self._activation = NotImplemented\n",
        "\n",
        "        super(ResidualBlock, self).__init__()\n",
        "\n",
        "    def build(self, ishape):\n",
        "        # TODO: fill in this function\n",
        "        raise NotImplementedError\n",
        "        super(ResidualBlock, self).build(ishape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # TODO: fill in this function\n",
        "        raise NotImplementedError\n",
        "        return self._activation(x)\n",
        "\n",
        "\"\"\"Testing\"\"\"\n",
        "vis = train.take(10)\n",
        "for image, t in vis:\n",
        "    x = ResidualBlock(filters = 3)(image)\n",
        "    y = ResidualBlock(filters = 32, downsample=True)(image)\n",
        "    print(x.shape, y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "random value:  fill in the blank\n",
            "random value:  fill in the blank\n",
            "(1, 28, 28, 3) (1, 14, 14, 32)\n",
            "random value:  fill in the blank\n",
            "(1, 28, 28, 3) (1, 14, 14, 32)\n",
            "random value:  fill in the blank\n",
            "(1, 28, 28, 3) (1, 14, 14, 32)\n",
            "random value:  fill in the blank\n",
            "(1, 28, 28, 3) (1, 14, 14, 32)\n",
            "random value:  fill in the blank\n",
            "(1, 28, 28, 3) (1, 14, 14, 32)\n",
            "random value:  fill in the blank\n",
            "(1, 28, 28, 3) (1, 14, 14, 32)\n",
            "random value:  fill in the blank\n",
            "(1, 28, 28, 3) (1, 14, 14, 32)\n",
            "random value:  fill in the blank\n",
            "(1, 28, 28, 3) (1, 14, 14, 32)\n",
            "random value:  fill in the blank\n",
            "(1, 28, 28, 3) (1, 14, 14, 32)\n",
            "random value:  fill in the blank\n",
            "(1, 28, 28, 3) (1, 14, 14, 32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cx5eYyqo75Wm"
      },
      "source": [
        "# CELL 4\n",
        "'''\n",
        "testing your pipeline and you custom block together \n",
        "\n",
        "mnist input shape  = (28, 28, 1)\n",
        "\n",
        "DEEP MIND Implementation -> very stable\n",
        " -> loss function is more stable \n",
        " -> batch norm causes exploding gradients \n",
        "'''\n",
        "\n",
        "@tf.function\n",
        "def ae_loss(x, x_reconstruction, loss = ks.losses.mse):\n",
        "    return -tf.reduce_sum(loss(x, x_reconstruction), axis = [1, 2, 3])\n",
        "\n",
        "@tf.function\n",
        "def regularize(z, mu, log_sigma):\n",
        "    # mu = tf.reduce_sum(mu, axis = [1])\n",
        "    # sigma = tf.reduce_sum(sigma, axis = [1])\n",
        "    # term = tf.math.exp(sigma) + (mu ** 2) - 1 - sigma\n",
        "    log2pi = tf.math.log(2. * np.pi)\n",
        "    term = -0.5 * (((z - mu) ** 2.) * tf.math.exp(-log_sigma) + log_sigma + log2pi)\n",
        "    return tf.reduce_sum(term, axis = 1)\n",
        "\n",
        "@tf.function\n",
        "def vae_loss(term1, term2):\n",
        "    return -tf.reduce_mean(term1 + term2)\n",
        "\n",
        "class VAE(ks.Model):\n",
        "    def __init__(self, input_shape, latent_size = None, latent_dims = None, batch_size = 40):\n",
        "        super(VAE, self).__init__()\n",
        "        self.ishape = input_shape\n",
        "        self.latent_size = latent_size\n",
        "        self.batch_size = batch_size\n",
        "        self.encoder = None\n",
        "        self.decoder = None\n",
        "\n",
        "        print(latent_dims)\n",
        "        self.encoder = self.get_encoder(latent_size)\n",
        "        self.decoder = self.get_decoder(latent_dims)\n",
        "        return\n",
        "    \n",
        "    def get_encoder(self, latent_size):\n",
        "        '''\n",
        "        NOTE\n",
        "        ----\n",
        "        the encoder is a simple NN, CNN, RNN, or transformer structure that maps to a latent vector\n",
        "        the details of the network do not need to be specific, but can be anything\n",
        "        the attributes of this network:\n",
        "            - downsample the input vector \n",
        "            - map to a vector\n",
        "        '''\n",
        "        encoder = ks.Sequential()\n",
        "        encoder.add(ks.layers.Conv2D(32, kernel_size = (3,3), strides = (1,1), padding = \"valid\"))\n",
        "        encoder.add(ks.layers.BatchNormalization())\n",
        "        encoder.add(ks.layers.ReLU())\n",
        "        encoder.add(ResidualBlock(64, downsample=True))\n",
        "        encoder.add(ks.layers.Flatten())\n",
        "        encoder.add(ks.layers.Dense(512))\n",
        "        encoder.add(ks.layers.BatchNormalization())\n",
        "        encoder.add(ks.layers.ReLU())\n",
        "\n",
        "        # use latent_size + latent_size, so that half the vector is learing the z_mu (mean) other half is learning z_sigma (standard deviation)\n",
        "        encoder.add(ks.layers.Dense(latent_size + latent_size))\n",
        "        return encoder\n",
        "    \n",
        "    def get_decoder(self, dimension):\n",
        "        vec_size = prod(dimension)\n",
        "        decoder = ks.Sequential()\n",
        "        decoder.add(ks.layers.Dense(vec_size))\n",
        "        decoder.add(ks.layers.ReLU())\n",
        "        decoder.add(ks.layers.Reshape(dimension, input_shape = (None, self.latent_size, )))\n",
        "        decoder.add(ks.layers.Conv2DTranspose(64, kernel_size = (3,3), strides = (1,1), padding = \"valid\"))\n",
        "        decoder.add(ks.layers.ReLU())\n",
        "        decoder.add(ks.layers.Conv2DTranspose(64, kernel_size = (3,3), strides = (2,2), padding = \"valid\"))\n",
        "        decoder.add(ks.layers.ReLU())\n",
        "        decoder.add(ks.layers.Conv2DTranspose(32, kernel_size = (3,3), strides = (1,1), padding = \"valid\"))\n",
        "        decoder.add(ks.layers.ReLU())\n",
        "        decoder.add(ks.layers.Conv2DTranspose(1, kernel_size = (2,2), strides = (1,1), padding = \"valid\"))\n",
        "        return decoder\n",
        "\n",
        "    def reparameterize(self, z_mu, z_sigma):\n",
        "        sample = tf.random.normal(shape = (self.batch_size, z_mu.shape[-1]), mean = 0, stddev=1)\n",
        "        z = z_mu + tf.math.exp(z_sigma) * sample\n",
        "        return z\n",
        "\n",
        "    def decode(self, inputs):\n",
        "        self.batch_size = tf.shape(inputs)[0]\n",
        "        x = self.decoder(inputs)\n",
        "        return x\n",
        "\n",
        "    def call(self, inputs):\n",
        "        self.batch_size = tf.shape(inputs)[0]\n",
        "        z_full = self.encoder(inputs)\n",
        "\n",
        "        # num_or_size_splits is a scalar to the value gets split evenly in the same way every time\n",
        "        z_mu, z_sigma = tf.split(z_full, num_or_size_splits=2, axis = -1)\n",
        "        z = self.reparameterize(z_mu, z_sigma)\n",
        "        x = self.decoder(z)\n",
        "        return x, z, z_mu, z_sigma\n",
        "\n",
        "    def predict(self, inputs):\n",
        "        self.batch_size = tf.shape(inputs)[0]\n",
        "        z_full = self.encoder(inputs)\n",
        "        z_mu, z_sigma = tf.split(z_full, num_or_size_splits=2, axis = -1)\n",
        "        z = self.reparameterize(z_mu, z_sigma)\n",
        "        return z\n",
        "\n",
        "    def train_step(self, data):\n",
        "        # use with model.fit\n",
        "        # unpack the input data\n",
        "        x, x_reconstruction = data\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            # call self or model to make a prediction\n",
        "            x_hat, z, z_mu, z_sigma = self(x, training = True)\n",
        "            p_xz = ae_loss(x, x_hat, loss = tf.nn.sigmoid_cross_entropy_with_logits) # computes sigmoid for you \n",
        "            p_z = regularize(z, 0., 0.)\n",
        "            q_zx = regularize(z, z_mu, z_sigma)\n",
        "            loss = self.compiled_loss(p_xz, p_z - q_zx , regularization_losses=self.losses)\n",
        "\n",
        "        trainable_vars = self.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "\n",
        "        self.compiled_metrics.update_state(x, x_hat)\n",
        "        ret = {m.name: m.result() for m in self.metrics}\n",
        "        ret.update({\"loss2\": p_xz, \"reg\": q_zx})\n",
        "        return ret\n",
        "    \n",
        "\n",
        "\n",
        "EPOCHS = 20\n",
        "BATCH_SIZE = 80\n",
        "LATENT_SIZE = 2\n",
        "loss = vae_loss\n",
        "optimizer = ks.optimizers.Adam()\n",
        "printing = False\n",
        "losses = []\n",
        "\n",
        "    \n",
        "(train, test), info = tfds.load(\"mnist\", split = ['train', 'test'], with_info=True, shuffle_files=True, as_supervised = True)\n",
        "train = train.map(lambda x, y: preprocess(x, y)).batch(40)\n",
        "test = test.map(lambda x, y: preprocess(x, y)).batch(1)\n",
        "\n",
        "# if the output looks blurry, increase the epochs or comment out the randome crops. \n",
        "# we will still use random crops to test that the data pipeline is functional, so dont delete it\n",
        "# if you comment it out, in the machine learning question google doc, just leave a \n",
        "# note for this part indicating that you choose to comment out the random crops\n",
        "# commenting it out will not affect your possition on the team\n",
        "\n",
        "model = VAE(input_shape=(28,28,1), latent_size = LATENT_SIZE, latent_dims = (10,10,2))\n",
        "model.compile(loss=loss, optimizer=optimizer, metrics = [tf.keras.metrics.MeanSquaredError()])\n",
        "epoch_data = model.fit(train, epochs=EPOCHS, validation_data=test)\n",
        "\n",
        "# if you dont want to train again, just this in a new cell\n",
        "display(test, model, x0 = 0, y0 = 1, n = 30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXfS-gXon0wE"
      },
      "source": [
        "#CELL 5\n",
        "\"\"\"\n",
        "Write the provided/incorrect loss function in `ae_loss`.\n",
        "\n",
        "Instructions for this code block, questions can be found\n",
        "on the google doc associated with this assignment.\n",
        "\n",
        "To re-iterate the instruction doc: This step is not required, but it will be\n",
        "extra-credit for the competition (see Rock-Paper-Scissors CNN in doc).\n",
        "\"\"\"\n",
        "\n",
        "@tf.function\n",
        "def ae_loss(x, x_reconstruction, mu, log_sigma, batch_size, latent_size):\n",
        "    # TODO: fill in this function\n",
        "    raise NotImplementedError\n",
        "\n",
        "class VAE(ks.Model):\n",
        "    def __init__(self, input_shape, latent_size = None, latent_dims = None, batch_size = 40):\n",
        "        super(VAE, self).__init__()\n",
        "        self.ishape = input_shape\n",
        "        self.latent_size = latent_size\n",
        "        self.batch_size = batch_size\n",
        "        self.encoder = None\n",
        "        self.decoder = None\n",
        "\n",
        "        self.encoder = self.get_encoder(latent_size)\n",
        "        self.decoder = self.get_decoder(latent_dims)\n",
        "\n",
        "        print(latent_dims)\n",
        "        return\n",
        "    \n",
        "    def get_encoder(self, latent_size):\n",
        "        '''\n",
        "        NOTE\n",
        "        ----\n",
        "        the encoder is a simple NN, CNN, RNN, or transformer structure that maps to a latent vector\n",
        "        the details of the network do not need to be specific, but can be anything\n",
        "        the attributes of this network:\n",
        "            - downsample the input vector \n",
        "            - map to a vector\n",
        "        '''\n",
        "        encoder = ks.Sequential()\n",
        "        encoder.add(ks.layers.Conv2D(32, kernel_size = (3,3), strides = (1,1), padding = \"valid\"))\n",
        "        encoder.add(ks.layers.BatchNormalization())\n",
        "        encoder.add(ks.layers.ReLU())\n",
        "        encoder.add(ResidualBlock(64, downsample=True))\n",
        "        encoder.add(ks.layers.Flatten())\n",
        "        encoder.add(ks.layers.Dense(512))\n",
        "        encoder.add(ks.layers.BatchNormalization())\n",
        "        encoder.add(ks.layers.ReLU())\n",
        "\n",
        "        # use latent_size + latent_size, so that half the vector is learing the z_mu (mean) other half is learning z_sigma (standard deviation)\n",
        "        encoder.add(ks.layers.Dense(latent_size + latent_size))\n",
        "        return encoder\n",
        "    \n",
        "    def get_decoder(self, dimension):\n",
        "        vec_size = prod(dimension)\n",
        "        decoder = ks.Sequential()\n",
        "        decoder.add(ks.layers.Dense(vec_size))\n",
        "        decoder.add(ks.layers.ReLU())\n",
        "        decoder.add(ks.layers.Reshape(dimension, input_shape = (None, self.latent_size, )))\n",
        "        decoder.add(ks.layers.Conv2DTranspose(64, kernel_size = (3,3), strides = (1,1), padding = \"valid\"))\n",
        "        decoder.add(ks.layers.ReLU())\n",
        "        decoder.add(ks.layers.Conv2DTranspose(64, kernel_size = (3,3), strides = (2,2), padding = \"valid\"))\n",
        "        decoder.add(ks.layers.ReLU())\n",
        "        decoder.add(ks.layers.Conv2DTranspose(32, kernel_size = (3,3), strides = (1,1), padding = \"valid\"))\n",
        "        decoder.add(ks.layers.ReLU())\n",
        "        decoder.add(ks.layers.Conv2DTranspose(1, kernel_size = (2,2), strides = (1,1), padding = \"valid\", activation = 'sigmoid'))\n",
        "        return decoder\n",
        "\n",
        "    def reparameterize(self, z_mu, z_sigma):\n",
        "        sample = tf.random.normal(shape = (self.batch_size, z_mu.shape[-1]))\n",
        "        z = z_mu + tf.math.exp(z_sigma) * sample\n",
        "        return z\n",
        "\n",
        "    def decode(self, inputs):\n",
        "        x = self.decoder(inputs)\n",
        "        return x\n",
        "\n",
        "    def call(self, inputs):\n",
        "        self.batch_size = tf.shape(inputs)[0]\n",
        "        z_full = self.encoder(inputs)\n",
        "        # num_or_size_splits is a scalar to the value gets split evenly in the same way every time\n",
        "        z_mu, z_sigma = tf.split(z_full, num_or_size_splits=2, axis = -1)\n",
        "        z = self.reparameterize(z_mu, z_sigma)\n",
        "        x = self.decoder(z)\n",
        "        return x, z, z_mu, z_sigma\n",
        "\n",
        "    def predict(self, inputs):\n",
        "        self.batch_size = tf.shape(inputs)[0]\n",
        "        tf.print(self.batch_size)\n",
        "        z_full = self.encoder(inputs)\n",
        "        z_mu, z_sigma = tf.split(z_full, num_or_size_splits=2, axis = -1)\n",
        "        z = self.reparameterize(z_mu, z_sigma)\n",
        "        return z\n",
        "\n",
        "    def train_step(self, data):\n",
        "        # use with model.fit\n",
        "        # unpack the input data\n",
        "        x, x_reconstruction = data\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            # call self or model to make a prediction\n",
        "            x_hat, z, z_mu, z_sigma = self(x, training = True)\n",
        "            loss, kl = ae_loss(x, x_hat, z_mu, z_sigma, tf.shape(x)[0], self.latent_size)\n",
        "\n",
        "        trainable_vars = self.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "\n",
        "        self.compiled_metrics.update_state(x, x_hat)\n",
        "        ret = {m.name: m.result() for m in self.metrics}\n",
        "        ret.update({\"loss\":loss, \"regular\": kl})\n",
        "        return ret\n",
        "    \n",
        "(train, test), info = tfds.load(\"mnist\", split = ['train', 'test'], with_info=True, shuffle_files=True, as_supervised = True)\n",
        "train = train.map(preprocess).batch(40)\n",
        "test = test.map(preprocess).batch(1)\n",
        "\n",
        "# if the output looks blurry, increase the epochs or comment out the random crops. \n",
        "# we will still use random crops to test that the data pipeline is functional, so dont delete it\n",
        "# if you comment it out, in the machine learning question google doc, just leave a \n",
        "# note for this part indicating that you choose to comment out the random crops\n",
        "# commenting it out will not affect your possition on the team\n",
        "\n",
        "LATENT_SIZE = 2\n",
        "optimizer = 'rmsprop'\n",
        "model = VAE(input_shape=(28,28,1), latent_size = LATENT_SIZE, latent_dims = (10, 10, 2))\n",
        "model.compile(loss=None, optimizer=optimizer, metrics = [tf.keras.metrics.MeanSquaredError(), tf.keras.metrics.BinaryCrossentropy()])\n",
        "epoch_data = model.fit(train, epochs=20, validation_data=test)\n",
        "\n",
        "# if you dont want to train again, just this in a new cell\n",
        "display(test, model, x0 = 0, y0 = 1, n = 30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNXk1aQkO0rg"
      },
      "source": [
        "#CELL 6\n",
        "\"\"\"\n",
        "Write your (the corrected) loss function in `ae_loss`.\n",
        "\n",
        "Instructions for this code block, questions can be found\n",
        "on the google doc associated with this assignment.\n",
        "\n",
        "To re-iterate the instruction doc: This step is not required, but it will be\n",
        "extra-credit for the competition (see Rock-Paper-Scissors CNN in doc).\n",
        "\"\"\"\n",
        "\n",
        "@tf.function\n",
        "def ae_loss(x, x_reconstruction, mu, log_sigma, batch_size, latent_size):\n",
        "    # TODO: fill in this function\n",
        "    raise NotImplementedError\n",
        "\n",
        "class VAE(ks.Model):\n",
        "    def __init__(self, input_shape, latent_size = None, latent_dims = None, batch_size = 40):\n",
        "        super(VAE, self).__init__()\n",
        "        self.ishape = input_shape\n",
        "        self.latent_size = latent_size\n",
        "        self.batch_size = batch_size\n",
        "        self.encoder = None\n",
        "        self.decoder = None\n",
        "\n",
        "        self.encoder = self.get_encoder(latent_size)\n",
        "        self.decoder = self.get_decoder(latent_dims)\n",
        "\n",
        "        print(latent_dims)\n",
        "        return\n",
        "    \n",
        "    def get_encoder(self, latent_size):\n",
        "        '''\n",
        "        NOTE\n",
        "        ----\n",
        "        the encoder is a simple NN, CNN, RNN, or transformer structure that maps to a latent vector\n",
        "        the details of the network do not need to be specific, but can be anything\n",
        "        the attributes of this network:\n",
        "            - downsample the input vector \n",
        "            - map to a vector\n",
        "        '''\n",
        "        encoder = ks.Sequential()\n",
        "        encoder.add(ks.layers.Conv2D(32, kernel_size = (3,3), strides = (1,1), padding = \"valid\"))\n",
        "        encoder.add(ks.layers.BatchNormalization())\n",
        "        encoder.add(ks.layers.ReLU())\n",
        "        encoder.add(ResidualBlock(64, downsample=True))\n",
        "        encoder.add(ks.layers.Flatten())\n",
        "        encoder.add(ks.layers.Dense(512))\n",
        "        encoder.add(ks.layers.BatchNormalization())\n",
        "        encoder.add(ks.layers.ReLU())\n",
        "\n",
        "        # use latent_size + latent_size, so that half the vector is learing the z_mu (mean) other half is learning z_sigma (standard deviation)\n",
        "        encoder.add(ks.layers.Dense(latent_size + latent_size))\n",
        "        return encoder\n",
        "    \n",
        "    def get_decoder(self, dimension):\n",
        "        vec_size = prod(dimension)\n",
        "        decoder = ks.Sequential()\n",
        "        decoder.add(ks.layers.Dense(vec_size))\n",
        "        decoder.add(ks.layers.ReLU())\n",
        "        decoder.add(ks.layers.Reshape(dimension, input_shape = (None, self.latent_size, )))\n",
        "        decoder.add(ks.layers.Conv2DTranspose(64, kernel_size = (3,3), strides = (1,1), padding = \"valid\"))\n",
        "        decoder.add(ks.layers.ReLU())\n",
        "        decoder.add(ks.layers.Conv2DTranspose(64, kernel_size = (3,3), strides = (2,2), padding = \"valid\"))\n",
        "        decoder.add(ks.layers.ReLU())\n",
        "        decoder.add(ks.layers.Conv2DTranspose(32, kernel_size = (3,3), strides = (1,1), padding = \"valid\"))\n",
        "        decoder.add(ks.layers.ReLU())\n",
        "        decoder.add(ks.layers.Conv2DTranspose(1, kernel_size = (2,2), strides = (1,1), padding = \"valid\", activation = 'sigmoid'))\n",
        "        return decoder\n",
        "\n",
        "    def reparameterize(self, z_mu, z_sigma):\n",
        "        sample = tf.random.normal(shape = (self.batch_size, z_mu.shape[-1]))\n",
        "        z = z_mu + tf.math.exp(z_sigma) * sample\n",
        "        return z\n",
        "\n",
        "    def decode(self, inputs):\n",
        "        x = self.decoder(inputs)\n",
        "        return x\n",
        "\n",
        "    def call(self, inputs):\n",
        "        self.batch_size = tf.shape(inputs)[0]\n",
        "        z_full = self.encoder(inputs)\n",
        "        # num_or_size_splits is a scalar to the value gets split evenly in the same way every time\n",
        "        z_mu, z_sigma = tf.split(z_full, num_or_size_splits=2, axis = -1)\n",
        "        z = self.reparameterize(z_mu, z_sigma)\n",
        "        x = self.decoder(z)\n",
        "        return x, z, z_mu, z_sigma\n",
        "\n",
        "    def predict(self, inputs):\n",
        "        self.batch_size = tf.shape(inputs)[0]\n",
        "        tf.print(self.batch_size)\n",
        "        z_full = self.encoder(inputs)\n",
        "        z_mu, z_sigma = tf.split(z_full, num_or_size_splits=2, axis = -1)\n",
        "        z = self.reparameterize(z_mu, z_sigma)\n",
        "        return z\n",
        "\n",
        "    def train_step(self, data):\n",
        "        # use with model.fit\n",
        "        # unpack the input data\n",
        "        x, x_reconstruction = data\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            # call self or model to make a prediction\n",
        "            x_hat, z, z_mu, z_sigma = self(x, training = True)\n",
        "            loss, kl = ae_loss(x, x_hat, z_mu, z_sigma, tf.shape(x)[0], self.latent_size)\n",
        "\n",
        "        trainable_vars = self.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "\n",
        "        self.compiled_metrics.update_state(x, x_hat)\n",
        "        ret = {m.name: m.result() for m in self.metrics}\n",
        "        ret.update({\"loss\":loss, \"regular\": kl})\n",
        "        return ret\n",
        "    \n",
        "(train, test), info = tfds.load(\"mnist\", split = ['train', 'test'], with_info=True, shuffle_files=True, as_supervised = True)\n",
        "train = train.map(preprocess).batch(40)\n",
        "test = test.map(preprocess).batch(1)\n",
        "\n",
        "# if the output looks blurry, increase the epochs or comment out the random crops. \n",
        "# we will still use random crops to test that the data pipeline is functional, so dont delete it\n",
        "# if you comment it out, in the machine learning question google doc, just leave a \n",
        "# note for this part indicating that you choose to comment out the random crops\n",
        "# commenting it out will not affect your possition on the team\n",
        "\n",
        "LATENT_SIZE = 2\n",
        "optimizer = 'rmsprop'\n",
        "model = VAE(input_shape=(28,28,1), latent_size = LATENT_SIZE, latent_dims = (10, 10, 2))\n",
        "model.compile(loss=None, optimizer=optimizer, metrics = [tf.keras.metrics.MeanSquaredError(), tf.keras.metrics.BinaryCrossentropy()])\n",
        "epoch_data = model.fit(train, epochs=20, validation_data=test)\n",
        "\n",
        "# if you dont want to train again, just this in a new cell\n",
        "display(test, model, x0 = 0, y0 = 1, n = 30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOXL2mRSb7rs"
      },
      "source": [
        "# CELL 7\n",
        "# More data pipe lines YAY!!!\n",
        "'''\n",
        "copy the pipeline above \n",
        "\n",
        "to the pipeline:\n",
        "    - add a random flip\n",
        "    - random hue, max alpha = 0.3\n",
        "    - random brightness, max alpha = 0.3\n",
        "    - random_contrast, min = 0.9, max = 1.1\n",
        "'''\n",
        "def preprocess(image: tf.Tensor, label: tf.Tensor, depth = 3, disp: bool = False):\n",
        "    shape = tf.shape(image)\n",
        "    image = tf.cast(image, dtype = tf.float32)\n",
        "    image = image/255\n",
        "\n",
        "    crop_1 = tf.cast(tf.shape(image)[0] * 22/28, dtype = tf.int32)\n",
        "    crop_2 = tf.cast(tf.shape(image)[1] * 26/28, dtype = tf.int32)\n",
        "\n",
        "    \"\"\"\n",
        "    copy code from previous pipeline but use crop_1 and crop_2 as the range within which to generate a random number\n",
        "    \"\"\"\n",
        "\n",
        "    # new additions\n",
        "    if (tf.shape(image)[-1] == 3):\n",
        "        \"\"\"\n",
        "        add:\n",
        "            - random flip\n",
        "            - random hue, max alpha = 0.3\n",
        "            - random brightness, max alpha = 0.1\n",
        "            - random_contrast, min = 0.9, max = 1.1\n",
        "        \"\"\"\n",
        "\n",
        "    image = tf.image.resize(image, (shape[0], shape[1]))\n",
        "    label = tf.one_hot(label, depth)\n",
        "    if disp:\n",
        "        tf.print(\"shape: \", tf.shape(image))\n",
        "        tf.print(\"random value: \", randint)\n",
        "    return image, label\n",
        "\n",
        "\"\"\"script to load data set and print info\"\"\"\n",
        "(train, test), info = tfds.load(\"rock_paper_scissors\", split = ['train', 'test'], with_info=True, shuffle_files=True, as_supervised = True)\n",
        "print(info)\n",
        "\n",
        "\"\"\" Test \"\"\"\n",
        "train = train.map(lambda x, y: preprocess(x, y, disp = True)).batch(1)\n",
        "for i, (image, label) in enumerate(train):\n",
        "    if (tf.shape(image)[-1] != 3):\n",
        "        plt.imshow(image[0, ..., 0])\n",
        "    else:\n",
        "        plt.imshow(image[0, ...])\n",
        "    plt.show()\n",
        "    print(label)\n",
        "    if i > 10:\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PG9_JtWSdqG0"
      },
      "source": [
        "# CELL 8\n",
        "model = ks.Sequential()\n",
        "model.add(ks.layers.Conv2D(\"\"\"fill this in\"\"\"))# inital feature extraction, get the most important information, so less filters is better, do a single down sample\n",
        "\"\"\"\n",
        "\n",
        "BUILD A Conv NN: \n",
        "\n",
        "ADD LAYERS TO BUILD A FULL CNN\n",
        "    - add layers to the sequential model using model.add(<the layer you choose>)\n",
        "JUST MAKE SURE YOU USE SOFTMAX AS THE LAST LAYER, the soft max layer is provided\n",
        "\n",
        "competition:\n",
        "    - the student with the lowest number of parameters and accuracy >= 90% on the validation set will win $15\n",
        "    - if multiple people have the same number of parameters, the money will be split between the winners, or it will go to the student with higher accuracy.\n",
        "\n",
        "\"\"\"\n",
        "model.add(ks.layers.Activation(activation = \"softmax\"))\n",
        "\n",
        "model.build(input_shape=(None, 300, 300, 3))\n",
        "model.summary()\n",
        "\n",
        "\"\"\"script to load data set and print info\"\"\"\n",
        "(train, test), info = tfds.load(\"rock_paper_scissors\", split = ['train', 'test'], with_info=True, shuffle_files=True, as_supervised = True)\n",
        "train = train.map(lambda x, y: preprocess(x, y, disp = False)).batch(40)\n",
        "test = test.map(lambda x, y: preprocess(x, y, disp = False)).batch(40)\n",
        "\n",
        "EPOCHS = 100\n",
        "optimizer = NotImplemented\n",
        "loss_fn = NotImplemented\n",
        "metrics_fn = ks.metrics.CategoricalAccuracy()\n",
        "\n",
        "\"\"\"script that will be used to test you model\"\"\"\n",
        "model.compile(optimizer=optimizer, loss = loss_fn, metrics)\n",
        "model.fit(train, validation_data = test, epochs=EPOCHS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjcwPnzygc0J"
      },
      "source": [
        "# CELL 9\n",
        "del model\n",
        "model = ks.Sequential()\n",
        "model.add(ks.layers.Conv2D(\"\"\"copy from cell above\"\"\"))\n",
        "\"\"\"\n",
        "COPY your model from above if you want this to test correctly\n",
        "\"\"\"\n",
        "model.add(ks.layers.Activation(activation = \"softmax\"))\n",
        "\n",
        "(train, test), info = tfds.load(\"rock_paper_scissors\", split = ['train', 'test'], with_info=True, shuffle_files=True, as_supervised = True)\n",
        "train = train.map(lambda x, y: preprocess(x, y, disp = False)).batch(40)\n",
        "test = test.map(lambda x, y: preprocess(x, y, disp = False)).batch(40)\n",
        "\n",
        "EPOCHS = 100\n",
        "optimizer = NotImplemented\n",
        "loss_fn = NotImplemented\n",
        "metrics_fn = ks.metrics.CategoricalAccuracy()\n",
        "\n",
        "\n",
        "# building a custom training loop\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"epoch: {epoch}\")\n",
        "    \"\"\"\n",
        "    initialize something to hold all the values of loss and accuracy for validation and training\n",
        "    \"\"\"\n",
        "    for \"\"\"fill in\"\"\" in train:\n",
        "        \"\"\"\n",
        "        construct the training loop that would have been appied by calling model.fit\n",
        "        \"\"\"\n",
        "    print(f\"avg loss :: {tf.math.reduce_mean(loss)}, avg accuracy :: {tf.math.reduce_mean(accuracy)}\", end = \"\\n\")\n",
        "\n",
        "    for \"\"\"fill in\"\"\" in test: \n",
        "        \"\"\"\n",
        "        construct the validation loop that would be used to test if the accuracy is similar on the validation set\n",
        "        \"\"\"\n",
        "    print(f\"avg val loss :: {tf.math.reduce_mean(val_loss)}, avg val accuracy :: {tf.math.reduce_mean(val_accuracy)}\", end = \"\\n\")\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lY9E-bi2lTjQ"
      },
      "source": [
        "# CELL 10\n",
        "\"\"\"visualize/ test the trained model\"\"\"\n",
        "(train, test), info = tfds.load(\"rock_paper_scissors\", split = ['train', 'test'], with_info=True, shuffle_files=True, as_supervised = True)\n",
        "test = test.map(lambda x, y: preprocess(x, y, disp = False)).batch(1)\n",
        "\n",
        "class_dict = {0:\"rock\", 1:\"paper\", 2:\"scissors\"}\n",
        "for i, (image, label) in enumerate(test):\n",
        "    classif = model(image)\n",
        "    if (tf.shape(image)[-1] != 3):\n",
        "        plt.imshow(image[0, ..., 0])\n",
        "    else:\n",
        "        plt.imshow(image[0, ...])\n",
        "    plt.show()\n",
        "    print(class_dict[int(tf.math.argmax(classif, axis = -1)[0])], class_dict[int(tf.math.argmax(label, axis = -1)[0])])\n",
        "\n",
        "    if i > 10:\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 11\n",
        "from IPython.display import display, Javascript, Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode, b64encode\n",
        "import cv2\n",
        "import numpy as np\n",
        "import PIL\n",
        "import io\n",
        "import html\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "# function to convert the JavaScript object into an OpenCV image\n",
        "def js_to_image(js_reply):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          js_reply: JavaScript object containing image from webcam\n",
        "  Returns:\n",
        "          img: OpenCV BGR image\n",
        "  \"\"\"\n",
        "  # decode base64 image\n",
        "  image_bytes = b64decode(js_reply.split(',')[1])\n",
        "  # convert bytes to numpy array\n",
        "  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "  # decode numpy array into OpenCV BGR image\n",
        "  img = cv2.imdecode(jpg_as_np, flags=1)\n",
        "\n",
        "  return img\n",
        "  def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "\n",
        "  # get photo data\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  # get OpenCV format image\n",
        "  img = js_to_image(data) \n",
        "  # casts the image to the tensor\n",
        "  camera_image = tf.cast(img, tf.float32)/255\n",
        "  camera_image = tf.image.resize(camera_image, (300,300))\n",
        "  camera_image = tf.reshape(camera_image, [1, 300, 300, 3])\n",
        "\n",
        "  class_dict = {0:\"rock\", 1:\"paper\", 2:\"scissors\"}\n",
        "  classif = model(camera_image)\n",
        "  print('You have showed: ' + class_dict[int(tf.math.argmax(classif, axis = -1)[0])])\n",
        "\n",
        "  return filename"
      ],
      "metadata": {
        "id": "v88YPKMZ3_hy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TAKE A PICTURE\n",
        "\n",
        "# Run this cell to turn on the camera and take a picture of your hand. Make sure to have a white background.\n",
        "\n",
        "try:\n",
        "  filename = take_photo('photo.jpg')\n",
        "  \n",
        "  # Show the image which was just taken.\n",
        "  display(Image(filename))\n",
        "except Exception as err:\n",
        "  # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "  # grant the page permission to access it.\n",
        "  print(str(err))"
      ],
      "metadata": {
        "id": "c_joyEL04Sc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" \n",
        "We trained the model using 3D generated images and tested it using the same database. \n",
        "Now we are using the model in a real world scenario. Feel free to share your thoughts on the pros and cons of this approach.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "bAZa1MVdA1u2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 12\n",
        "\"\"\" Read the papers provided in the onboarding task and write your answers below.\n",
        "1. YOLOX & YOLOv3\n",
        "\n",
        "\n",
        "2. Mesh R-CNN\n",
        "\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ItYlWAwguMEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 13\n",
        "\"\"\" Read the TFMG Tech Report (https://arxiv.org/abs/2107.00821) and answer the following questions)\n",
        "\n",
        "1. What is the purpose of the Tensorflow Model Garden?\n",
        "2. How does this team's goals differ from those of NeurIPS?\n",
        "3. Explain the difference between a custom layer and a custom block.\n",
        "4. Explain the importance of training and evaluation checks.\n",
        "5. Which folder would a custom layer belong in according to the Tensorflow Model Garden organizational structure?\n",
        "6. Why is metric evaluation alone not sufficient to confirm that a model has been successfully reimplemented?\n",
        "7. What TensorFlow function should be used when computing values whose gradients can be safely ignored?\n",
        "8. Describe the purpose of the datapipeline and its 3 components.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "hzKrU1025_MC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}